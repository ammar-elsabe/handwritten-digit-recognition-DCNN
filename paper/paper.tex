\documentclass[conference]{IEEEtran}
\usepackage{amsmath}
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage[caption=false]{subfig}
\usepackage{import}
\usepackage{amsmath}
\usepackage{listings}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage[hidelinks]{hyperref}
\hypersetup{
    bookmarksopen=true,
}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\begin{document}

\title{Handwritten Digit Recognition Using Deep Convolutional Neural Network*}




\author{\IEEEauthorblockN{Ammar Elsabe}
\IEEEauthorblockA{
    U19100452@sharjah.ac.ae\\
    University ID: U19100452
}

\and

\IEEEauthorblockN{Mohamed Alzaabi}
\IEEEauthorblockA{
    U17105281@sharjah.ac.ae\\
    University ID: U17105281
}

\and

\IEEEauthorblockN{Abdulaziz Abdullatif}
\IEEEauthorblockA{
    U18103708@sharjah.ac.ae\\
    University ID: U18103708
}}

\maketitle
\begin{abstract}
    A Convolutional Neural Network (CNN) is a powerful tool for image classification.\@ However, despite existing since the late 1980s, they have been majorly dormant until the mid-2000s, which is when computing power and large databases of labeled data started becoming more accessible thanks to GPU technology and the internet, respectively.\@ This paper pits the use of a Deep Convolutional Neural Network (DCNN) against the MNIST database of handwritten digit images, and as will be seen by the end of the paper, the performance of these networks on a (cheap, consumer) GPU is simply a marvel of engineering, nearing human--level accuracy.
\end{abstract}

\section{Introduction}
\footnotetext[1]{Code can be found at \href{github.com/ammar-elsabe/handwritten-digit-recognition-DCNN.git}{\texttt{github.com/ammar-elsabe/handwritten-\\digit-recognition-DCNN.git}}}
Computer vision is an interdisciplinary field that asks the question: ``Can a computer learn from pictures?''.\@ After all, a picture is worth a thousand words.\@ One interesting field of computer vision is Optical Character Recognition (OCR), which aims to identify the characters in documents. Given the ubiquity of handwritten documents in human transactions, OCR of documents have invaluable practical worth. Optical character recognition is a science that enables to translate various types of documents or images into analyzable, editable and searchable data.
During last decade, researchers have used artificial intelligence / machine learning tools to automatically analyze handwritten and printed documents in order to convert them into electronic format.
An OCR system depends mainly, on the extraction of
features and discrimination/classification of these features
(based on patterns). Handwritten OCR have received increasing attention as a subfield of OCR.\@ It is further categorized into offline\cite{article} and online systems\cite{Connell2001}.
\blindtext

\section{Convolutional Neural Networks}
A convolutional neural network consists of an input layer, hidden layers and an output layer. In any feed-forward neural network, any middle layers are called hidden because their inputs and outputs are masked by the activation function and final convolution. In a convolutional neural network, the hidden layers include layers that perform convolutions. Typically this includes a layer that performs a dot product of the convolution kernel with the layer's input matrix. As the convolution kernel slides along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This is followed by other layers such as pooling layers, fully connected layers, and normalization layers.
\subsection{Convolutional Layers}
In a CNN, the input is a tensor with a shape: (number of inputs) x (input height) x (input width) x (input channels). After passing through a convolutional layer, the image becomes abstracted to a feature map, also called an activation map, with shape: (number of inputs) x (feature map height) x (feature map width) x (feature map channels).
\par Convolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus.

\subsection{Pooling Layers}
\blindtext

\subsection{Fully Connected Layers}
\blindtext

\section{The MNIST Dataset}
The Modified National Institute of Standards and Technology (MNIST) database is a database of handwritten digits \cite{6296535} that is a classic benchmark for image recognition.\@ It is also widely used in the machine learning world\cite{Platt1998}.\@ It consists of a training set of 60,000 images and a test set of 10,000 images.\@ The training set is used to train the network, and the test set is used to evaluate its performance.\@ The images are $28 \times 28$ pixels, and the labels are 0 to 9. It is a subset of a larger set available from NIST.\@ It was created in 1998 as a combination of two of their databases, Special Database 1 and 3, which contained digits written by high school students and empoyees of the United States Census Bureau, respectively.\@ Half of the database was taken from ``Special Database 1'', and the other half was taken from ``Special Database 3''. The original creators kept a list of the methods tested on it\cite{726791, mnist}, and in their original paper they used a Support Vector Machine (SVM) to achieve an accuracy of 99.2\%\cite{1265868}.
\par
There exists another database called Extended MNIST (EMNIST) created to the successor to MNIST\cite{emnist} created from NIST ``Special Database 19'', which includes the handwritten uppercase and lowercase letters, as well as digits.\cite{emnist2} EMNIST was created only using the digits subset of ``Special Database 19''. In the following sections of this paper, we use MNIST (not EMNIST) for our CNN.\@

\section{Training the model}
We used Google's TensorFlow API\cite{tensorflow2015-whitepaper} in Python to train the model on a consumer computer with the following specefications:
\begin{itemize}
    \item CPU: Intel i5-8400
    \item GPU: NVIDIA GeForce GTX 1060
    \item RAM: 16GB
\end{itemize}
Instead of preprocessing the data, we elected to not preprocess the data at all (except for some automatic tuning and batching to speed up the training), but to have the model take the raw grayscale $28 \times 28$ pixel images.\@ We decided to do that in order to show how powerful DCNNs can be and how good they can be at feature extraction.\@
As such, our neural network (Figure \ref{fig:cnn_architecture}) starts with a rescaling layer, which is nothing but normalizing the grayscale values from $[0, 255]$ to $[0, 1]$. It is then followed by a 2D convolutional layer with $28 \, 3 \times 3$ kernels, outputting 28 feature maps. The feature maps are then pooled with a $2 \times 2$ pool--size max pooling layer, cutting the amount of pixels in each feature map by $4$. We then apply batch normalization\cite{batchnorm} to reduce overfitting, and redo the above process once more before flattening the image.\@
Following the flattening of the feature maps, we are left with a 1 dimensional vector of size 700, which is then inputted to a series of fully connected layers, with the number of perceptrons in each layer going $700 \to 128 \to 128 \to 10$. All the layers in the neural network used the relu activation function, except the last one which uses softmax to output its predictions.
The losss function used was categorical crossentropy, which is:
\begin{equation}
    J(\textbf{w}) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \text{log}(\hat{y}_i) + (1-y_i) \text{log}(1-\hat{y}_i) \right]
\end{equation}
and the optimizer used was the ``Adam'' optimizer, which is a version of stochastic gradient descent\cite{adam} that we hyperparameterized with the default learning rate of $0.001$
%The architecture used is shown in Figure \ref{fig:cnn_architecture}.  
\begin{figure}[!htp]
    \centering
    \def\svgwidth{\columnwidth}
    \scriptsize
    \import{./figs/}{cnn_architecture.pdf_tex}
    \caption{The CNN architecture used to train the model}\label{fig:cnn_architecture}
\end{figure}
The callbacks used were the following:
\begin{lstlisting}[language=Python]
tf.keras.callbacks.EarlyStopping( 
    monitor='val_loss',
    patience=5,
),
tf.keras.callbacks.ModelCheckpoint( 
    'model.h5',
    monitor='val_loss',
    save_best_only=True,
    verbose=1)
\end{lstlisting}
That is to say that training stops once it plateaus (with 5 epochs and no improvement), and that we save the best performing model (in terms of validation loss), which we later load and use for the predictions.\@ With our architecture and even our cheap, widely available specifications, training took merely a limit, and the per--epoch progress is shown in Figure \ref{fig:perepoch}
\begin{figure}[!htp]
    \centering
    \scriptsize
    \subfloat[Training and validation accuracy\label{performance:accuracy}]{
        \def\svgwidth{0.5\columnwidth}
        \import{./figs/}{accuracy.pdf_tex}
    }
    \subfloat[Training and validation loss\label{performance:loss}]{
        \def\svgwidth{0.5\columnwidth}
        \import{./figs/}{loss.pdf_tex}
    }
    \caption{The per--epoch progress of the model's performance }\label{fig:perepoch}
\end{figure}
\par From Figure \ref{fig:perepoch}, we can see that the model reaches a high, near--human accuracy, but following the first epoch the rate of improvement decreases, and following the third epoch it begins to overfit, where the training loss and accuracies are steadily improving but the validation training and loss are in fact getting \textit{worse}.

\section{Model Evaluation}
Following training the model, we can define the trained model mathematically as a bayesian probability distribution over the 10 classes: $\hat{p}(y | x)$; the probability of a label $y$ given an image $x$.
Testing the model on the test set nets us with a 2D matrix $a$, with $10000$ rows and $10$ columns.\@ The $i$\textsuperscript{th} row corresponds to the $i$\textsuperscript{th} image in the test set, and the $j$\textsuperscript{th} column corresponds to a digit $j$.\@ The value of $a_{i,j}$ is the probability that the $i$\textsuperscript{th} image contains the $j$\textsuperscript{th} digit, or mathematically:
\begin{equation}
    a_{i,j} = \hat{p}(y = j | x = i)
\end{equation}
We define the predicted label for an image $i$ as the label with the highest probability outputted by the model:
\begin{equation}
    y_i = \argmax_j a_{i,j}
\end{equation}
Where $y$ is the set of predicted outputs. Let $x$ be the set of actual labels, and let $C_{sd}$ be the set of images belonging to the digit $d$ in the set $s$ (for example: $C_{y0}$ is the set of images that are predicted to be 0/labeled as 0 in the set $y$):
\begin{equation}
    C_{sd} = \{i \in \{1, 2, \;\ldots, 10000\} : s_i = d\}
    \;\label{eq:setofimages}
\end{equation}
\par A confusion matrix, also known as an error matrix, is a square matrix of size $n \times n$ where $n$ is the number of classes. It is a specifici table layout that allows the visualization of a model's performance. Each row of the matrix represents the instances in an actual class, while each column represents the instances in a predicted class\cite{Stehman1997}. With $C$ defined in (\ref{eq:setofimages}), we can mathematically denote the confusion matrix as:
\begin{equation}
    %\scriptstyle
    M = \begin{bmatrix}
        |C_{x0} \cap C_{y0}| &  \cdots & |C_{x0} \cap C_{y9}| \\
        %|C_{x1} \cap C_{y0}| &  \cdots & |C_{x1} \cap C_{y9}| \\
        \vdots & \ddots & \vdots \\
        |C_{x9} \cap C_{y0}| &  \cdots & |C_{x9} \cap C_{y9}|
    \end{bmatrix}
\end{equation}
Plotting $M$ on a heatmap, we can see the confusion matrix in Figure \ref{fig:confusion_matrix}.
\begin{figure}[!htp]
    \centering
    \def\svgwidth{\columnwidth}
    \scriptsize
    \import{./figs/}{confusion_matrix.pdf_tex}
    \caption{Confusion matrix of the trained model}\label{fig:confusion_matrix}
\end{figure}
\par With the confusion matrix computed, we can define accuracy as the following equation using the confusion matrix:
\begin{equation}
    \text{accuracy} = \frac{\sum_{i = 0}^9 k_{ii}}{\sum_{i = 0}^9 \sum_{j = 0}^9 k_{ij}} \times 100
\end{equation}
where $k_{xy}$ represents an element in the $x^\text{th}$ row and $y^\text{th}$ column of the confusion matrix, in other words it is the sum of the elements in the diagonal of the confusion matrix (correct predictions), dividied by the total sum (total number of samples in the dataset). Calculating the values nets us a diagonal sum of $9908$, and since the test split of the MNIST dataset is $10000$ images, that gives us an accuracy of $99.08\%$.
\par
We can also calculate the per--digit accuracy of a digit $i$ as:
\begin{equation}
    \text{accuracy}_{i} = \frac{k_{ii}}{\sum_{j = 0}^9 k_{ij}} \times 100
\end{equation}
which gives us the values needed to plot the accuracy of each digit in the bar chart shown in Figure \ref{fig:bar}.
\begin{figure}[!htp]
    \centering
    \def\svgwidth{\columnwidth}
    \import{./figs/}{bar_plot.pdf_tex}
    \caption{The accuracy of the model at detecting each digit}\label{fig:bar}
\end{figure}
\par From the bar chart, we can see that the highest accuracy is achieved by the model detecting the digit $4$ at an accuracy of $99.8982\%$, and the lowest accuracy is detecting the digit $9$ with an accuracy of $98.1169\%$.
\section{Conclusion}
In conclusion, we believe that DCNNs will have an important role in upcoming OCR technologies.\@ The results of our experiment are phenomonal, near--human accurate, and with very little cost.\@ There is the issue of our model overfitting too quickly (after just 3 epochs of training), but that can be attributed to the neural network architecture, and with some fine tuning can and has been brought to even more accurate levels.\@

\bibliographystyle{IEEEtran}
\bibliography{paper.bib}

\end{document}
